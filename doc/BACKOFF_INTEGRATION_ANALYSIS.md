# Backoff Integration Analysis: Synchronous Sleep vs. Separate Node

**Date:** 2026-02-21 (Analysis); Phase 3 Implemented 2026-02-21
**Status:** âœ… Design Implemented (see [Phase 3 Implementation](#phase-3-implementation-february-2026) below)
**Category:** Retry Logic & Resilience

> **This document analyzes the design trade-offs** between embedded backoff, a separate node, and async scheduling. **The recommended "async scheduler" design with state-driven timing has been implemented in Phase 3** â€” see the epilogue for details on how the recommendations became reality.

---

## Phase 3 Implementation (February 2026)

âœ… **The recommended "Best Solution" design has been implemented.** Backoff now uses:
- **State-driven scheduling** with `retry_not_before` timestamp (not embedded sleep)
- **Separate `retry_scheduler` node** in the graph (visible, testable, observable)
- **Both sync and async implementations** ready for future graph conversion

### How It Works (Phase 3)

**error_handler node** (decision only, no sleep):
```python
# From agent/nodes/error_handler.py (lines 68-86)
if action == "retry":
    new_retry_count = retry_count + 1
    new_delay = min(suggested_delay, 300)  # Cap at 5 minutes

    # Schedule retry â€” don't sleep
    now = time.time()
    retry_not_before = now + new_delay

    logger.info("Error handler: RETRY #%d (scheduled for %d)",
                new_retry_count, int(retry_not_before))

    updates["retry_count"] = new_retry_count
    updates["retry_delay_seconds"] = new_delay
    updates["retry_not_before"] = retry_not_before  # â† Key change
```

**retry_scheduler node** (timing enforcement):
```python
# From agent/nodes/retry_scheduler.py (lines 30-66)
def retry_scheduler(state: AgentState) -> dict:
    """Apply scheduled backoff before retrying."""
    retry_not_before = state.get("retry_not_before")

    if retry_not_before is None:
        return {}

    now = time.time()
    wait_time = retry_not_before - now

    if wait_time > 0:
        logger.info("Retry backoff: waiting %.1f seconds", wait_time)
        time.sleep(wait_time)  # Sync version

    return {"retry_not_before": None}  # Clear after backoff

# Async version available: retry_scheduler_async()
```

### Graph Routing (Phase 3)

```python
# From agent/graph.py
builder.add_edge("error_handler", "retry_scheduler")
builder.add_edge("retry_scheduler", "pick_next_domain")  # On retry action
```

**Flow:**
```
error_handler (decides action, schedules time)
  â†“
retry_scheduler (enforces backoff delay)
  â†“
pick_next_domain (loops back to retry)
```

---

## Design Analysis

### Current Design: Embedded Sleep âœ“

**How it works:**
```
error_handler node:
  1. LLM analyzes error
  2. Decides: retry/skip/abort
  3. If retry: time.sleep(delay_seconds)  â† Synchronous sleep
  4. Update state with new retry_count
  5. Return to graph
  6. Graph routes to pick_next_domain
```

**Advantages:**
- âœ… Simple to implement
- âœ… Backoff is guaranteed (happens before next attempt)
- âœ… Exponential backoff works correctly
- âœ… State field is updated for observability

**Disadvantages:**
- ðŸ”´ **Blocks LangGraph execution** â€” entire graph thread sleeps
- ðŸ”´ **Hard to test** â€” tests must mock/skip `time.sleep()`
- ðŸ”´ **Poor observability** â€” sleep is invisible to LangGraph tracing
- ðŸ”´ **Not async-friendly** â€” can't use `await asyncio.sleep()` if graph becomes async
- ðŸ”´ **Inefficient for distributed systems** â€” blocks worker thread

---

## Alternative: Separate Backoff Node

### Design

```python
# Separate backoff node
def apply_backoff(state: AgentState) -> dict:
    """Apply the retry delay before attempting next action."""
    delay = state.get("retry_delay_seconds", 5)

    logger.info("Waiting %d seconds before retry...", delay)
    time.sleep(delay)

    return {}  # Pass through, state unchanged

# Graph routing
builder.add_edge("error_handler", "backoff_handler")
builder.add_edge("backoff_handler", "pick_next_domain")
```

**Advantages:**
- âœ… Separates concerns (error decision vs. backoff timing)
- âœ… Visible in LangGraph execution trace
- âœ… Testable in isolation
- âœ… Observable (can measure backoff duration)
- âœ… Easier to async-ify later

**Disadvantages:**
- âŒ Extra node in graph (minor overhead)
- âŒ Slightly more complex routing
- âŒ Still synchronous (blocks thread)

---

## Best Solution: Async Backoff with State-Driven Timing

### Design (Future-Proof)

```python
# No sleep at all â€” use state-based backoff scheduling

async def error_handler_async(state: AgentState) -> dict:
    """Analyze error and decide action (no sleep)."""
    # ... LLM analysis ...

    if action == "retry":
        # Record when to retry, but don't sleep
        import time as time_module
        now = time_module.time()
        retry_at = now + suggested_delay

        return {
            "error_analysis": raw,
            "retry_count": new_retry_count,
            "retry_delay_seconds": new_delay,
            "retry_not_before": retry_at,  # Schedule retry
        }

# Scheduler node (optional, smart retry)
async def retry_scheduler(state: AgentState) -> dict:
    """Check if enough time has passed before retrying."""
    import time as time_module

    if state.get("action") == "retry":
        retry_not_before = state.get("retry_not_before")
        now = time_module.time()

        if now < retry_not_before:
            wait_time = retry_not_before - now
            logger.info("Waiting %.1fs more before retry...", wait_time)
            await asyncio.sleep(wait_time)

    return {}
```

**Advantages:**
- âœ… Non-blocking (can use async/await)
- âœ… Fully observable (backoff in state)
- âœ… Easy to test (no time mocking needed)
- âœ… Scalable (async scheduler can manage 1000s of retries)
- âœ… Supports distributed execution (workers can coordinate timing)

---

## Comparison

| Aspect | Current (Embedded Sleep) | Separate Node | Async Scheduler (Recommended) |
|--------|---|---|---|
| **Implementation** | âœ… Simple | ðŸŸ¡ Moderate | ðŸŸ¡ Moderate |
| **Observable** | ðŸ”´ No (hidden in node) | ðŸŸ¢ Yes (separate node) | ðŸŸ¢ Yes (in state) |
| **Testable** | ðŸŸ¡ Hard (mock sleep) | ðŸŸ¢ Easy (mock graph) | ðŸŸ¢ Easy (no real time) |
| **Blocking** | ðŸ”´ Yes (sync sleep) | ðŸ”´ Yes (sync sleep) | ðŸŸ¢ No (async) |
| **Async-friendly** | ðŸ”´ No | ðŸ”´ No | ðŸŸ¢ Yes |
| **Distributed-safe** | ðŸ”´ No (blocks worker) | ðŸ”´ No (blocks worker) | ðŸŸ¢ Yes (non-blocking) |
| **Scalability** | ðŸŸ¡ OK for < 10 domains | ðŸŸ¡ OK for < 10 domains | ðŸŸ¢ OK for 1000+ domains |

---

## Real-World Scenarios

### Scenario 1: High-Volume Retry

**100 domains, 10% fail on first attempt = 10 retries with 60s backoff each**

**Current design:**
```
Domain 1 fails â†’ error_handler sleeps 60s â†’ tries again
Domain 2 fails â†’ error_handler sleeps 60s â†’ tries again
Domain 3 fails â†’ error_handler sleeps 60s â†’ tries again
...
Total blocked time: 10 Ã— 60s = 600s (10 minutes)
Agent is idle during all sleeps
```

**Async scheduler design:**
```
Domain 1 fails â†’ error_handler records "retry_not_before: T+60s" (returns immediately)
Domain 2 fails â†’ error_handler records "retry_not_before: T+60s" (returns immediately)
Domain 3 fails â†’ error_handler records "retry_not_before: T+60s" (returns immediately)
Scheduler checks: "Is 60s elapsed? If not, wait. If yes, proceed."
Total blocked time: 0s (scheduler awaits, doesn't block)
```

### Scenario 2: Testing

**Current design:**
```python
def test_retry_with_backoff():
    # How to test the 60s sleep?
    with patch('time.sleep') as mock_sleep:
        result = error_handler(state)
        mock_sleep.assert_called_with(60)
    # Fragile: depends on implementation details
```

**Async scheduler design:**
```python
async def test_retry_with_backoff():
    result = await error_handler(state)
    assert result["retry_not_before"] == now + 60
    # No time mocking needed, just check the state value
```

---

## Implementation Status

### âœ… Phase 3: Separate Node + State-Driven Scheduling (Completed)

The implementation chose the **middle path** (better than embedded, preparation for async):

| Aspect | Chosen | Reason |
|--------|--------|--------|
| **Scheduling** | State-driven (`retry_not_before`) | Observable, testable, prepares for async |
| **Blocking** | Sync `time.sleep()` for now | Simple, works well for current domain counts |
| **Node structure** | Separate `retry_scheduler` node | Visible in graph traces, easy to upgrade |
| **Async support** | `retry_scheduler_async()` ready | Can be adopted when graph goes async (Phase 4+) |

### Benefits Realized

âœ… **Separates concerns** â€” error_handler decides, retry_scheduler enforces
âœ… **Visible in traces** â€” retry backoff appears as a distinct node in LangGraph execution
âœ… **Easy to test** â€” no time mocking; just check `retry_not_before` in state
âœ… **Observable** â€” backoff duration and scheduled time visible in logs and state
âœ… **Ready for async** â€” `retry_scheduler_async()` waits for Phase 4 graph conversion
âœ… **Scales to 100+ domains** â€” separate node doesn't block other domains (each domain progresses independently)

### Phase 4+ Future: Full Async

When the graph becomes `async`:
- Switch from `retry_scheduler()` to `retry_scheduler_async()`
- Replace `time.sleep(wait_time)` with `await asyncio.sleep(wait_time)`
- No other code changes needed â€” state structure already supports it

---

## Architecture Summary

**Graph flow (Phase 3):**

```
scanner (check expiry)
  â†“
planner (decide which domains)
  â†“
account (ACME registration)
  â†“
order (create order)
  â†“
challenge (HTTP-01 setup)
  â†“
csr (generate signing request)
  â†“
finalizer (complete ACME)
  â†“
storage (save cert/key)
  â†“ [error]
error_handler (LLM: retry/skip/abort)
  â”œâ”€ [retry] â†’ retry_scheduler (wait until retry_not_before)
  â”‚             â†“
  â”‚             pick_next_domain (loop back)
  â”‚
  â””â”€ [skip/abort] â†’ reporter (summary)
```

**Key files:**
- [`agent/nodes/error_handler.py`](../agent/nodes/error_handler.py) â€” Schedules retry (no sleep)
- [`agent/nodes/retry_scheduler.py`](../agent/nodes/retry_scheduler.py) â€” Enforces backoff timing
- [`agent/graph.py`](../agent/graph.py) â€” Graph topology
- [`ASYNC_SCHEDULER_IMPLEMENTATION_PLAN.md`](ASYNC_SCHEDULER_IMPLEMENTATION_PLAN.md) â€” Phase 3-4 roadmap

---

## Run Duration Bound

### Worst-Case Math (Default Config)

Each `retry_delay_seconds` doubles from the LLM's suggestion, but is hard-capped at 300 seconds (5 minutes) by the `error_handler`:

```python
new_delay = min(suggested_delay, 300)  # Cap at 5 minutes
```

With the **default config** (`MAX_RETRIES=3`, starting delay ~60s):

| Attempt | Delay | Cumulative wait |
|---------|-------|-----------------|
| Retry 1 | 60s   | 1 min           |
| Retry 2 | 120s  | 3 min           |
| Retry 3 | 240s  | 7 min           |
| **Total**| â€”    | **~7 minutes**  |

After 3 failures, the domain is added to `failed_renewals` and the run ends. The next scheduled run (default: daily at 06:00 UTC) will re-attempt it.

### Extended Config (`MAX_RETRIES=10`)

With the 300s cap, the sequence is: 60 + 120 + 240 + 300 + 300 + 300 + 300 + 300 + 300 + 300 = **2,520s â‰ˆ 42 minutes** per domain.

For 10 domains all failing: **up to ~7 hours** in the absolute worst case.

### Philosophy: Defer to the Next Run

A single agent run has an implicit bound: **if a domain cannot be renewed within `MAX_RETRIES` attempts, defer it to the next scheduled run**. The `failed_renewals` list records which domains were not renewed so operators can inspect logs.

This means:
- A run should not block indefinitely on a persistently broken domain
- The daily schedule provides a natural retry boundary
- Operators who raise `MAX_RETRIES` or start delays high should be aware of the cumulative wait time

**Guideline:** The default `MAX_RETRIES=3` gives ~7 minutes of backoff per domain before deferring. This is a good balance between transient error recovery and bounded run duration. If you raise `MAX_RETRIES` beyond 5, audit the resulting worst-case run time against your renewal window.

### No Current Wall-Clock Limit

There is currently no hard wall-clock limit on a single agent run. A future enhancement could add `max_run_duration_seconds` to config to enforce a ceiling, but this is not implemented. The 300s cap on individual delays is the only current bound.

---

## Related Documents

- [`ASYNC_SCHEDULER_IMPLEMENTATION_PLAN.md`](ASYNC_SCHEDULER_IMPLEMENTATION_PLAN.md) â€” Phase 3-4 implementation plan and roadmap
- [`SECURITY.md`](SECURITY.md#11-resilience-and-retry-safety) â€” Security implications of retry backoff
- [`agent/nodes/error_handler.py`](../agent/nodes/error_handler.py) â€” Scheduler decision logic
- [`agent/nodes/retry_scheduler.py`](../agent/nodes/retry_scheduler.py) â€” Backoff enforcement (sync + async)
- [`agent/graph.py`](../agent/graph.py) â€” Graph topology and routing
- [`agent/state.py`](../agent/state.py) â€” State schema with `retry_not_before`

---

## Epilogue: From Design Analysis to Implementation

This document was written as a **design analysis** before Phase 3 implementation. The evolution shows how deliberate architecture decisions are made:

### January 2026: The Problem
The initial implementation had `time.sleep()` embedded in `error_handler`. This blocked LangGraph execution and was hard to test.

### February 2026: The Analysis
This document was written to explore three approaches:
1. Keep embedded sleep (simple, but blocks execution)
2. Separate backoff node (visible, but still blocks)
3. State-driven async scheduling (observable, testable, non-blocking ready)

### February 2026: The Implementation (Phase 3)
The team implemented approach #3 with a hybrid strategy:
- **State-driven timing** using `retry_not_before` timestamp âœ…
- **Separate `retry_scheduler` node** for visibility and testability âœ…
- **Both sync and async versions** prepared for Phase 4 âœ…
- **No blocking of other domains** â€” each domain progresses independently âœ…

### The Result
- 46/46 tests passing
- Backoff is visible in LangGraph execution traces
- Easy to test without mocking `time`
- Ready to convert to async when graph converts (Phase 4+)
- Scales to 100+ domains per renewal cycle

### Key Lesson
Good architecture isn't about "perfect" solutions â€” it's about **deliberate trade-offs**. By choosing state-driven scheduling with a separate node, the team:
- Solved the immediate problem (observability, testability)
- Prepared for future scaling (async conversion)
- Maintained simplicity (sync `time.sleep()` for now)
- Documented the rationale (this file)

This is why design analysis documents matter: they capture the thinking process so future maintainers understand *why* decisions were made, not just *what* was implemented.
